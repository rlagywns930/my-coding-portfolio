# 🏠 House Price Prediction 프로젝트

## 📌 프로젝트 개요  
이 프로젝트는 Kaggle의 **"House Prices - Advanced Regression Techniques"** 데이터를 활용하여  
주택의 다양한 특성(면적, 건축 연도, 품질 등)을 기반으로 **주택 가격(SalePrice)** 을 예측하는 회귀 모델을 개발한 것입니다.  
모델 성능 향상뿐만 아니라, 실무에 적용 가능한 데이터 처리 및 해석력 향상에 집중했습니다.

---

## 🛠 사용 기술 및 라이브러리  
- Python (pandas, numpy, matplotlib, seaborn 등)  
- scikit-learn (Preprocessing, Model Selection, Evaluation)  
- XGBoost Regressor  
- Feature Engineering, 인코딩, 정규화  
- 교차검증 및 하이퍼파라미터 튜닝  
- RMSLE를 사용한 평가

---

## 📂 프로젝트 구성  

| 파일명                           | 설명                                         |
|----------------------------------|----------------------------------------------|
| `01. EDA.md`                     | 탐색적 데이터 분석 및 시각화                    |
| `02. 결측치 처리.md`            | 컬럼별 결측치 파악 및 대체 전략 적용              |
| `03. 이상치 제거.md`            | 이상치 탐지 및 제거                            |
| `04. Feature engineering.md`     | 파생 변수 생성, 변수 선택, 변수 정리              |
| `05. 인코딩.md`                  | 범주형 변수 인코딩 (Label, One-Hot 등)         |
| `07. 모델링.md`                  | XGBoost 모델링, 튜닝, 평가                      |
| `08. 최종 제출 파일.md`          | 예측 결과 저장 및 `submission.csv` 생성         |
| `09. 최종 해석 및 분석.md`       | 모델 해석 및 향후 개선 방향 정리                 |
| `README.md`                      | 전체 프로젝트 개요 문서                         |

---

## 🧹 데이터 전처리 및 특징

- **결측치 처리**:  
  - `None`, `0`, 평균/최빈값 등 상황에 맞는 전략 적용  
  - 수치형/범주형 구분하여 일관성 있게 처리  

- **이상치 제거**:  
  - `GrLivArea` 등에서 명백한 이상값 제거하여 모델 안정성 확보  

- **타깃 변수 변환**:  
  - `SalePrice`는 로그 변환 (`np.log1p`)하여 정규성 확보  
  - 예측 결과는 역변환 (`np.expm1`)으로 원래 단위로 복원  

---

## 🤖 모델링 및 결과

- **모델**: `XGBoost Regressor`  
- **하이퍼파라미터 튜닝**:  
  - `learning_rate`, `max_depth`, `n_estimators` 등 조정  
  - `GridSearchCV`로 최적 모델 탐색  

- **성능 평가 지표**:  
  - `RMSLE` (Root Mean Squared Log Error)  
  - 로그 스케일에서의 예측 정확도를 측정

| 평가 항목       | 값           |
|----------------|--------------|
| RMSLE (Train)  | **0.1116**   |
| Kaggle 점수     | **0.13741**  |

> 로그 변환 후 예측 정확도가 향상되었으며, Kaggle 기준에서도 준수한 성능을 기록

---

## 📌 실행 순서

1. `01. EDA.md` → 데이터 탐색 및 기본 통계 확인  
2. `02~05.md` → 결측치 처리, 이상치 제거, 피처 엔지니어링  
3. `07. 모델링.md` → XGBoost 모델 학습 및 평가  
4. `08. 최종 제출 파일.md` → `submission.csv` 생성  
5. `09. 최종 해석 및 분석.md` → 결과 해석 및 개선 방향 제시  

---

## 🔍 배운 점 및 인사이트

- **로그 변환**을 통해 타깃 변수 정규화 → 회귀 모델 안정성 향상  
- **결측치 처리 및 피처 엔지니어링**은 모델 성능에 매우 큰 영향  
- **XGBoost**는 복잡한 구조에서도 뛰어난 예측 성능을 보임  
- 향후에는 **Stacking / Ensemble 모델**이나 **Optuna 기반 튜닝**을 통해 성능 향상 가능성 존재  

---

## 💬 프로젝트 요약  

이 프로젝트는 단순한 회귀 문제 해결을 넘어,  
**전처리 → 모델링 → 평가 → 해석**까지 머신러닝 전 과정을 실전처럼 경험하는 데 중점을 두었습니다.  
실제 업무 환경에서도 확장 가능한 형태로 구성되어 있으며,  
데이터 과학 포트폴리오로서 실용성과 완성도를 모두 갖춘 프로젝트입니다.

---

감사합니다!
